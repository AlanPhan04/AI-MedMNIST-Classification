{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "# from hyperparam_tuning import *\n",
    "from deap import base, creator, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "# train_data_path = os.path.join(os.path.dirname(__file__), \"../../../data/preprocessed/train_data.npz\")\n",
    "\n",
    "# Load the dataset\n",
    "# Load preprocessed data\n",
    "data = np.load(\"C:\\\\Users\\\\Alan Phan\\\\Desktop\\\\Bach Khoa Studies\\\\HK242\\\\Machine Learning\\\\Assignments\\\\AI-MedMNIST-Classification\\\\AI-MedMNIST-Classification\\\\data\\\\preprocessed\\\\train_data.npz\")\n",
    "x_train, y_train = data[\"x_train\"], data[\"y_train\"].ravel()\n",
    "data = np.load(\"C:\\\\Users\\\\Alan Phan\\\\Desktop\\\\Bach Khoa Studies\\\\HK242\\\\Machine Learning\\\\Assignments\\\\AI-MedMNIST-Classification\\\\AI-MedMNIST-Classification\\\\data\\\\preprocessed\\\\test_data.npz\")\n",
    "x_test, y_test = data[\"x_test\"], data[\"y_test\"].ravel()\n",
    "# Define a smaller, optimized parameter grid\n",
    "param_grid1 = {\n",
    "    \"var_smoothing\": [10**i for i in range(-5, 5)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t200   \n",
      "1  \t120   \n",
      "2  \t110   \n",
      "3  \t112   \n",
      "4  \t117   \n",
      "5  \t123   \n",
      "6  \t117   \n",
      "7  \t113   \n",
      "8  \t132   \n",
      "9  \t133   \n",
      "10 \t108   \n",
      "11 \t111   \n",
      "12 \t113   \n",
      "13 \t101   \n",
      "14 \t129   \n",
      "15 \t97    \n",
      "16 \t131   \n",
      "17 \t111   \n",
      "18 \t106   \n",
      "19 \t120   \n",
      "20 \t120   \n",
      "21 \t120   \n"
     ]
    }
   ],
   "source": [
    "# Define fitness function\n",
    "def fitness_function(params):\n",
    "    var_smoothing = 100 ** params[0]\n",
    "    model = GaussianNB(var_smoothing=var_smoothing)\n",
    "    model.fit(x_train, y_train)\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "    return (accuracy,)\n",
    "\n",
    "# Genetic Algorithm Setup\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "IND_SIZE = 1  # One parameter to optimize\n",
    "POP_SIZE = 200\n",
    "NGEN = 100\n",
    "MUTPB = 0.2\n",
    "CXPB = 0.5\n",
    "\n",
    "# Toolbox setup\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", random.uniform, -9, 0)  # log10(var_smoothing)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=IND_SIZE)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", fitness_function)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# Run Genetic Algorithm\n",
    "population = toolbox.population(n=POP_SIZE)\n",
    "algorithms.eaSimple(population, toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=NGEN, \n",
    "                    stats=None, halloffame=None, verbose=True)\n",
    "\n",
    "# Get best individual\n",
    "best_ind = tools.selBest(population, k=2)[1]\n",
    "best_var_smoothing = 10 ** best_ind[0]\n",
    "print(f\"Best var_smoothing: {best_var_smoothing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GaussianNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train final model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m final_model \u001b[38;5;241m=\u001b[39m \u001b[43mGaussianNB\u001b[49m(var_smoothing\u001b[38;5;241m=\u001b[39mbest_var_smoothing)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# final_model.fit(x_train, y_train)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# test_accuracy = final_model.score(x_test, y_test)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# print(f\"Test Accuracy: {test_accuracy}\")\u001b[39;00m\n\u001b[0;32m      8\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(final_model, param_grid1, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GaussianNB' is not defined"
     ]
    }
   ],
   "source": [
    "# Train final model\n",
    "final_model = GaussianNB(var_smoothing=best_var_smoothing)\n",
    "# final_model.fit(x_train, y_train)\n",
    "# test_accuracy = final_model.score(x_test, y_test)\n",
    "# print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(final_model, param_grid1, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the model (this finds the best hyperparameters)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(x_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# save model\n",
    "model_save_path = os.path.join(\"models\", \"trained\", \"naive_bayes_with_ga_best_grid.pkl\")\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, model_save_path)\n",
    "print(f\"Model saved successfully at: {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
